import Documentation from "df/docs/layouts/documentation";

export default ({ children }) => (
  <Documentation title="Command line interface">{children}</Documentation>
);

## Installation

Dataform can be installed using <a target="_blank" href="https://www.npmjs.com/get-npm">NPM</a>:

```bash
npm i -g @dataform/cli
```

## Create a new project

To create a new project in the folder `new_project`:

```bash
WAREHOUSE=bigquery
dataform init $WAREHOUSE new_project
```

The currently supported warehouse types are: `[bigquery, postgres, redshift, snowflake]`

## Project structure

The default project structure is as follows:

```bash
project-dir
├── definitions
├── includes
├── package.json
└── dataform.json
```

## Define a table

The `definitions/` directory contains files that define [tables](/tables), [assertions](/assertions), and [operations](/operations).

To create a new table, create a new file such as `definitions/simplemodel.sql` with the following contents:

```sql
SELECT 1 AS test
```

## Compile your code

To check that your Dataform code compiles, run the `compile` command at the root of your project directory to get JSON dump of the compiled project:

```bash
dataform compile
```

You should see output similar to the following:

```json
{
    "tables": [
        {
            "name": "simplemodel",
            "type": "view",
            "target": {
                "schema": "dataform",
                "name": "simplemodel"
            },
            "query": "SELECT 1 AS test\n",
            "disabled": false,
            "fileName": "definitions/simplemodel.sql"
        }
    ],
    ...
}
```

## Create a credentials file

Dataform requires a credentials file in order to connect to your warehouse. Run the `init-creds` command at the root of your project
directory and Dataform will guide you through creation of a credentials file:

```bash
WAREHOUSE=bigquery
dataform init-creds $WAREHOUSE
```

This will result in a `.df-credentials.json` file being written to disk. Be careful not to check this file into any source control system you may be using.

## Run your code

In order to run your code, Dataform needs to access your data warehouse in order to determine its current state and tailor the resulting
SQL accordingly. If you'd like to see the final SQL that Dataform will run on your warehouse without actually running it, you can perform a dry run:

```bash
dataform run --dry-run
```

You should see something similar to the following:

```json
{
      ...
      "nodes": [
        {
            "name": "simplemodel",
            "tasks": [
                {
                    "type": "statement",
                    "statement": "\n        create or replace view \"dataform\".\"simplemodel\"\n        as SELECT 1 AS test;"
                }
            ],
            "type": "table",
            "target": {
                "schema": "dataform",
                "name": "simplemodel"
            },
            "tableType": "view"
        }
    ],
    ...
}
```

Removing the `--dry-run` option will result in the SQL being run in your warehouse:

```bash
dataform run
```

The `run` command's output will now include the run's execution status, including any errors encountered during the run.
