import Documentation from "df/docs/layouts/documentation";

export const meta = {
  title: "Command line interface",
  __filename
};

export default ({ children }) => (
  <Documentation {...meta}>{children}</Documentation>
);


## Installation

Dataform can be installed using <a target="_blank" href="https://www.npmjs.com/get-npm">NPM</a>:

```bash
npm i -g @dataform/cli
```

## Create a new project

To create a new `bigquery`, `postgres`, `redshift`, or `snowflake` project in the `new_project` directory, run the respective command:

```bash
dataform init bigquery new_project --gcloud-project-id<your-google-cloud-project-id>
- or -
dataform init postgres new_project
- or -
dataform init redshift new_project
- or -
dataform init snowflake new_project
```

### Project structure

Change directory into the newly-created `new_project` directory and take a look at your newly created project files:

```bash
cd new_project
ls
```

You should see the following structure:

```bash
project-dir
├── definitions
├── includes
├── package.json
└── dataform.json
```

## Define a dataset

The `definitions/` directory should be used for files that define [tables](/datasets), [assertions](/assertions), and [operations](/operations).

To create a new dataset, create a new file `definitions/example.sql`:

```bash
echo "SELECT 1 AS test" > definitions/example.sql
```

## Compile your code

To check that your Dataform code compiles, run the `compile` command at the root of your project directory to get JSON output of the compiled project:

```bash
dataform compile
```

You should see output similar to the following:

```bash
Compiling...

Compiled 1 action(s).
1 dataset(s):
  dataform.example [view]
```

## Create a credentials file

Dataform requires a credentials file in order to connect to your warehouse. Run the `init-creds` command and Dataform will guide you through credentials file creation:

```bash
dataform init-creds bigquery
- or -
dataform init-creds postgres
- or -
dataform init-creds redshift
- or -
dataform init-creds snowflake
```

A `.df-credentials.json` file will be written to disk containing your provided details.

Check out our [data warehouse setup guide](/platform_guides/set_up_datawarehouse) if you need help with the `init-creds` wizard.

<div className="bp3-callout bp3-icon-info-sign bp3-intent-warning" markdown="1">
  If using a source control system, we strongly recommend that you do not commit the{" "}
  <code>.df-credentials.json</code> file to your repository in order to protect these access
  credentials.
</div>

## Run your code

In order to run your code, Dataform needs to access your data warehouse in order to determine its current state and tailor the resulting
SQL accordingly. If you'd like to see the final SQL that Dataform will run on your warehouse without actually running it, you can perform a dry run:

```bash
dataform run --dry-run
```

You should see something similar to the following:

```bash
Compiling...

Compiled successfully.

Dry run (--dry-run) mode is turned on; not running the following actions against your warehouse:

1 dataset(s):
  dataform.example [table]
```

Removing the `--dry-run` option will result in the SQL being run in your warehouse:

```bash
dataform run
```

The `run` command's output will now include the run's execution status, including any errors encountered during the run:

```bash
Compiling...

Compiled successfully.

Running...

Dataset created:  dataform.example [view]
```

## Next steps

You have now seen how easy it is to use Dataform to publish simple datasets. Next, jump to our [guide](/guides/datasets) section.
